{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checksum Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This function calculates the checksum based on the contents of the file\n",
    "def get_checksum(file_content):\n",
    "    sha = hashlib.sha1()\n",
    "    for chunk in file_content.read(512):\n",
    "        sha.update(str(chunk).encode())\n",
    "    digest = sha.hexdigest()\n",
    "    return digest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We query the wiki to retrieve the names of all the DataDownload pages along with their Content URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Downloads:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Download</th>\n",
       "      <th>Content URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000BRAINS_ENIGMA3_Cortical_GWAS_Results</td>\n",
       "      <td>http://organicdatacuration.org/enigma_dev/imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADMRI_HV_Dataset_Download</td>\n",
       "      <td>http://organicdatacuration.org/enigma_new/imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADNI1_ENIGMA3_Cortical_GWAS_Results</td>\n",
       "      <td>http://organicdatacuration.org/enigma_dev/imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADNI1_Meta-2Danalysis_Dataset_Download</td>\n",
       "      <td>http://organicdatacuration.org/enigma_new/imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADNI1_test_APOE.csv</td>\n",
       "      <td>https://drive.google.com/open?id=1wjm3UdMpzDyz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ADNI1_test_Subcort_vol.csv</td>\n",
       "      <td>https://drive.google.com/open?id=1AWsVjRV5ESKW...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ADNI1_test_covariates.csv</td>\n",
       "      <td>https://drive.google.com/open?id=1cEHsD8e0hSaG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADNI2GO_ENIGMA3_Cortical_GWAS_Results</td>\n",
       "      <td>http://organicdatacuration.org/enigma_dev/imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ADNI2_Meta-2Danalysis_Dataset_Download</td>\n",
       "      <td>http://organicdatacuration.org/enigma_new/imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ADNI2_test_APOE.csv</td>\n",
       "      <td>https://drive.google.com/open?id=14m6kPBXSyM00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ADNI2_test_Subcort_vol.csv</td>\n",
       "      <td>https://drive.google.com/open?id=1uLnsoh8HOGxh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ADNI2_test_covariates.csv</td>\n",
       "      <td>https://drive.google.com/open?id=1JbtJxo3VZVEt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AIBL_test_APOE.csv</td>\n",
       "      <td>https://drive.google.com/open?id=1Er0Wq2fbv6hP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>AIBL_test_Subcort_vol.csv</td>\n",
       "      <td>https://drive.google.com/open?id=10CdtxqC7VIQc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>AIBL_test_covariates.csv</td>\n",
       "      <td>https://drive.google.com/open?id=1vtOOtValpCAq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ALSPACa_ENIGMA3_Cortical_GWAS_Results</td>\n",
       "      <td>http://organicdatacuration.org/enigma_dev/imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>APOE_Dataset_Sample_Download</td>\n",
       "      <td>http://organicdatacuration.org/enigma_new/imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>APOE_Regression_ADNI1_Dataset_Download</td>\n",
       "      <td>http://organicdatacuration.org/enigma_new/imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>APOE_Regression_ADNI2_Dataset_Download</td>\n",
       "      <td>http://organicdatacuration.org/enigma_new/imag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>APOE_Regression_DLBS_over_60yrs_Dataset_Download</td>\n",
       "      <td>http://organicdatacuration.org/enigma_new/imag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Data Download  \\\n",
       "0           1000BRAINS_ENIGMA3_Cortical_GWAS_Results   \n",
       "1                          ADMRI_HV_Dataset_Download   \n",
       "2                ADNI1_ENIGMA3_Cortical_GWAS_Results   \n",
       "3             ADNI1_Meta-2Danalysis_Dataset_Download   \n",
       "4                                ADNI1_test_APOE.csv   \n",
       "5                         ADNI1_test_Subcort_vol.csv   \n",
       "6                          ADNI1_test_covariates.csv   \n",
       "7              ADNI2GO_ENIGMA3_Cortical_GWAS_Results   \n",
       "8             ADNI2_Meta-2Danalysis_Dataset_Download   \n",
       "9                                ADNI2_test_APOE.csv   \n",
       "10                        ADNI2_test_Subcort_vol.csv   \n",
       "11                         ADNI2_test_covariates.csv   \n",
       "12                                AIBL_test_APOE.csv   \n",
       "13                         AIBL_test_Subcort_vol.csv   \n",
       "14                          AIBL_test_covariates.csv   \n",
       "15             ALSPACa_ENIGMA3_Cortical_GWAS_Results   \n",
       "16                      APOE_Dataset_Sample_Download   \n",
       "17            APOE_Regression_ADNI1_Dataset_Download   \n",
       "18            APOE_Regression_ADNI2_Dataset_Download   \n",
       "19  APOE_Regression_DLBS_over_60yrs_Dataset_Download   \n",
       "\n",
       "                                          Content URL  \n",
       "0   http://organicdatacuration.org/enigma_dev/imag...  \n",
       "1   http://organicdatacuration.org/enigma_new/imag...  \n",
       "2   http://organicdatacuration.org/enigma_dev/imag...  \n",
       "3   http://organicdatacuration.org/enigma_new/imag...  \n",
       "4   https://drive.google.com/open?id=1wjm3UdMpzDyz...  \n",
       "5   https://drive.google.com/open?id=1AWsVjRV5ESKW...  \n",
       "6   https://drive.google.com/open?id=1cEHsD8e0hSaG...  \n",
       "7   http://organicdatacuration.org/enigma_dev/imag...  \n",
       "8   http://organicdatacuration.org/enigma_new/imag...  \n",
       "9   https://drive.google.com/open?id=14m6kPBXSyM00...  \n",
       "10  https://drive.google.com/open?id=1uLnsoh8HOGxh...  \n",
       "11  https://drive.google.com/open?id=1JbtJxo3VZVEt...  \n",
       "12  https://drive.google.com/open?id=1Er0Wq2fbv6hP...  \n",
       "13  https://drive.google.com/open?id=10CdtxqC7VIQc...  \n",
       "14  https://drive.google.com/open?id=1vtOOtValpCAq...  \n",
       "15  http://organicdatacuration.org/enigma_dev/imag...  \n",
       "16  http://organicdatacuration.org/enigma_new/imag...  \n",
       "17  http://organicdatacuration.org/enigma_new/imag...  \n",
       "18  http://organicdatacuration.org/enigma_new/imag...  \n",
       "19  http://organicdatacuration.org/enigma_new/imag...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"PREFIX wiki: <http://localhost:8080/enigma_dev/index.php/Special:URIResolver/>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX enigma: <https://w3id.org/enigma#>\n",
    "SELECT ?w ?a\n",
    "WHERE \n",
    "{\n",
    "    ?w enigma:hasContentUrl ?a.\n",
    "}\n",
    "ORDER BY ?w\"\"\"\n",
    "\n",
    "response = requests.post(url, data = {'query': query})\n",
    "res = json.loads(response.text)\n",
    "\n",
    "query_results=[]\n",
    "print(\"Data Downloads:\")    \n",
    "for item in res['results']['bindings']:\n",
    "    w1 = item['w']['value'].replace(replace,\"\")\n",
    "    a1 = item['a']['value'].replace(replace,\"\")\n",
    "    query_results.append([w1,a1])\n",
    "\n",
    "df = pd.DataFrame(query_results)\n",
    "df.columns=['Data Download','Content URL']\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging into Wiki "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we log in to the wiki\n",
    "S = requests.Session()\n",
    "\n",
    "URL = \"http://organicdatacuration.org/enigma_dev/api.php\"\n",
    "\n",
    "# Retrieve login token\n",
    "PARAMS_0 = {\n",
    "    'action':\"query\",\n",
    "    'meta':\"tokens\",\n",
    "    'type':\"login\",\n",
    "    'format':\"json\"\n",
    "}\n",
    "\n",
    "DATA = S.get(url=URL, params=PARAMS_0).json()\n",
    "LOGIN_TOKEN = DATA['query']['tokens']['logintoken']\n",
    "\n",
    "print(\"Login Token: \",LOGIN_TOKEN)\n",
    "\n",
    "# Go to http://organicdatacuration.org/enigma_new/index.php/Special:BotPasswords for lgname & lgpassword, and add them below\n",
    "\n",
    "PARAMS_1 = {\n",
    "    'action':\"login\",\n",
    "    'lgname':\"\",\n",
    "    'lgpassword':\"\",\n",
    "    'lgtoken':LOGIN_TOKEN,\n",
    "    'format':\"json\"\n",
    "}\n",
    "\n",
    "DATA = S.post(URL, data=PARAMS_1).json()\n",
    "\n",
    "print(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Given a page and checksum value, the function writes the checksum value to the wiki\n",
    "\n",
    "def update_checksum_wiki(page_to_write,checksum_value):  \n",
    "    \n",
    "    text_to_append=\"{{#set:|Checksum (E)=\"+checksum_value+\"}}\"\n",
    "    PARAMS_2 = {\n",
    "        \"action\": \"query\",\n",
    "        \"meta\": \"tokens\",\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "\n",
    "    R = S.get(url=URL, params=PARAMS_2)\n",
    "    DATA = R.json()\n",
    "\n",
    "    CSRF_TOKEN = DATA['query']['tokens']['csrftoken']\n",
    "\n",
    "    # Step 4: POST request to edit a page\n",
    "\n",
    "    PARAMS_EDIT = {\n",
    "        \"action\": \"edit\",\n",
    "        \"title\": page_to_write,\n",
    "        \"section\": \"new\",\n",
    "        \"format\": \"json\",\n",
    "        \"text\": text_to_append,\n",
    "        \"token\": CSRF_TOKEN,\n",
    "    }\n",
    "\n",
    "    R = S.post(URL, data=PARAMS_EDIT)\n",
    "    DATA = R.json()\n",
    "\n",
    "    print(DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update Checksums in Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Cell to update all checksum values for the Data Downloads in the DataFrame\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    page_name = row[0]\n",
    "    #checksum is not calculated for files in google drive\n",
    "    if(page_name.endswith('.csv')):\n",
    "        continue\n",
    "    else:\n",
    "        url = row[1]\n",
    "        response = S.get(datadownload)\n",
    "        checksum = get_checksum(response.content)\n",
    "        update_checksum_wiki(page_name,checksum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
